{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part3-simple.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unghee/EECS598/blob/master/part3_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmMRNtjrAvLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e9e91013-9e14-4859-ce86-c73db9f46890"
      },
      "source": [
        "!pip install -q colormap\n",
        "!pip install -q easydev"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for colormap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.7MB/s \n",
            "\u001b[?25h  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdMu7oQ_Azq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "60776bbd-f047-43af-cb84-e8d429bf30fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zs_mu_Btw_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "13abaa6d-f1a8-408a-8329-bc65dfa02d3d"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import png\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from colormap.colors import Color, hex2rgb\n",
        "from sklearn.metrics import average_precision_score as ap_score\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from datasetcolab import FacadeDataset\n",
        "\n",
        "N_CLASS=5\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_class = N_CLASS\n",
        "        # self.layers = nn.Sequential(\n",
        "        #     #########################################\n",
        "        #     ###        TODO: Add more layers      ###\n",
        "        #     #########################################\n",
        "        #     # nn.Conv2d(3, self.n_class, 1, padding=0),\n",
        "        #     # nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # )\n",
        "\n",
        "\n",
        "        # self.down1=nn.Sequential(\n",
        "        self.conv0= nn.Conv2d(3, 64, 3, padding=1)\n",
        "\n",
        "        # down 1\n",
        "        self.pool1=nn.MaxPool2d(2)\n",
        "        self.conv1=nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.batchnorm1 =  nn.BatchNorm2d(128)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "        # down 2\n",
        "        self.pool2=nn.MaxPool2d(2)\n",
        "        self.conv2=nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.batchnorm2 =  nn.BatchNorm2d(128)\n",
        "        self.relu=nn.ReLU()    \n",
        "\n",
        "        # )\n",
        "\n",
        "        # up 1\n",
        "        self.up1=nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        # self.conv3 = nn.Conv2d(192, 128, 3, padding=1)\n",
        "        self.conv_up1 = nn.Conv2d(256, 64, 3, padding=1)\n",
        "\n",
        "        # up 2\n",
        "        self.up2=nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv_up2 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.outconv=nn.Conv2d(64, self.n_class, kernel_size=3, padding=1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.layers(x)\n",
        "        x0 = self.conv0(x) # torch.Size([1, 64, 256, 256])\n",
        "\n",
        "        # down1\n",
        "        x1 = self.pool1(x0)\n",
        "        x1 = self.conv1(x1)\n",
        "        x1 = self.batchnorm1(x1)\n",
        "        x1 = self.relu(x1) # torch.Size([1, 128, 128, 128])\n",
        "  \n",
        "        # down2\n",
        "        x2 = self.pool2(x1) #torch.Size([1, 128, 64, 64])\n",
        "        x2 = self.conv2(x2) #torch.Size([1, 128, 64, 64])\n",
        "        x2 = self.batchnorm2(x2)\n",
        "        x2 = self.relu(x2)\n",
        "\n",
        "        # up1\n",
        "        x = self.up1(x2) #torch.Size([1, 128, 128, 128])\n",
        "        x = torch.cat([x,x1],dim=1) #torch.Size([1, 256, 128, 128])\n",
        "        x = self.conv_up1 (x) #torch.Size([1, 64, 128, 128])\n",
        "\n",
        "        # up2\n",
        "        x = self.up2(x) #torch.Size([1, 64, 256, 256])\n",
        "        x = torch.cat([x,x0],dim=1) #torch.Size([1, 128, 256, 256])\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        logit = self.outconv(x)\n",
        "\n",
        "\n",
        "        # x1cs= self.up1(x1c)\n",
        "        # x2 = torch.cat([x0,x1cs],dim=1)\n",
        "        # x3 = self.conv3(x2)\n",
        "        # x4 = self.outconv(x3)\n",
        "\n",
        "\n",
        "        return logit\n",
        "\n",
        "\n",
        "def save_label(label, path):\n",
        "    '''\n",
        "    Function for ploting labels.\n",
        "    '''\n",
        "    colormap = [\n",
        "        '#000000',\n",
        "        '#0080FF',\n",
        "        '#80FF80',\n",
        "        '#FF8000',\n",
        "        '#FF0000',\n",
        "    ]\n",
        "    assert(np.max(label)<len(colormap))\n",
        "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
        "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
        "    with open(path, 'wb') as f:\n",
        "        w.write(f, label)\n",
        "\n",
        "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
        "    '''\n",
        "    Function for training.\n",
        "    '''\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    net = net.train()\n",
        "    for images, labels in tqdm(trainloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss = loss.item()\n",
        "    end = time.time()\n",
        "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
        "          (epoch, running_loss, end-start))\n",
        "\n",
        "def test(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Function for testing.\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)\n",
        "            loss = criterion(output, labels)\n",
        "            losses += loss.item()\n",
        "            cnt += 1\n",
        "    print(losses / cnt)\n",
        "    return (losses/cnt)\n",
        "\n",
        "\n",
        "def cal_AP(testloader, net, criterion, device):\n",
        "    '''\n",
        "    Calculate Average Precision\n",
        "    '''\n",
        "    losses = 0.\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        preds = [[] for _ in range(5)]\n",
        "        heatmaps = [[] for _ in range(5)]\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images).cpu().numpy()\n",
        "            for c in range(5):\n",
        "                preds[c].append(output[:, c].reshape(-1))\n",
        "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
        "\n",
        "        aps = []\n",
        "        for c in range(5):\n",
        "            preds[c] = np.concatenate(preds[c])\n",
        "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
        "            if heatmaps[c].max() == 0:\n",
        "                ap = float('nan')\n",
        "            else:\n",
        "                ap = ap_score(heatmaps[c], preds[c])\n",
        "                aps.append(ap)\n",
        "            print(\"AP = {}\".format(ap))\n",
        "\n",
        "    # print(losses / cnt)\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_result(testloader, net, device, folder='output_train'):\n",
        "    result = []\n",
        "    cnt = 1\n",
        "    with torch.no_grad():\n",
        "        net = net.eval()\n",
        "        cnt = 0\n",
        "        for images, labels in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = net(images)[0].cpu().numpy()\n",
        "            c, h, w = output.shape\n",
        "            assert(c == N_CLASS)\n",
        "            y = np.zeros((h,w)).astype('uint8')\n",
        "            for i in range(N_CLASS):\n",
        "                mask = output[i]>0.5\n",
        "                y[mask] = i\n",
        "            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
        "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
        "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
        "            plt.imsave(\n",
        "                './{}/x{}.png'.format(folder, cnt),\n",
        "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
        "\n",
        "            cnt += 1\n",
        "\n",
        "# def main():\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# TODO change data_range to include all train/evaluation/test data.\n",
        "# TODO adjust batch_size.\n",
        "train_data = FacadeDataset(flag='train', data_range=(0,20), onehot=False)\n",
        "train_loader = DataLoader(train_data, batch_size=1)\n",
        "test_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)\n",
        "test_loader = DataLoader(test_data, batch_size=1)\n",
        "ap_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)\n",
        "ap_loader = DataLoader(ap_data, batch_size=1)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load train dataset start\n",
            "    from: ./drive/My Drive/hw5/starter_set/\n",
            "    range: [0, 20)\n",
            "load dataset done\n",
            "load test_dev dataset start\n",
            "    from: ./drive/My Drive/hw5/starter_set/\n",
            "    range: [0, 114)\n",
            "load dataset done\n",
            "load test_dev dataset start\n",
            "    from: ./drive/My Drive/hw5/starter_set/\n",
            "    range: [0, 114)\n",
            "load dataset done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrFrx9Q6BFzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "002c8e8b-6502-4381-f4b9-22d6f5efa55f"
      },
      "source": [
        "\n",
        "\n",
        "name = 'starter_net'\n",
        "net = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss() #TODO decide loss\n",
        "optimizer = torch.optim.Adam(net.parameters(), 1e-3, weight_decay=1e-5)\n",
        "\n",
        "test(train_loader, net, criterion, device)\n",
        "print('\\nStart training')\n",
        "for epoch in range(10): #TODO decide epochs\n",
        "    print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
        "    train(train_loader, net, criterion, optimizer, device, epoch+1)\n",
        "    # TODO create your evaluation set, load the evaluation set and test on evaluation set\n",
        "    evaluation_loader = train_loader\n",
        "    test(evaluation_loader, net, criterion, device)\n",
        "\n",
        "print('\\nFinished Training, Testing on test set')\n",
        "test(test_loader, net, criterion, device)\n",
        "print('\\nGenerating Unlabeled Result')\n",
        "result = get_result(test_loader, net, device, folder='output_test')\n",
        "\n",
        "torch.save(net.state_dict(), './models/model_{}.pth'.format(name))\n",
        "\n",
        "cal_AP(ap_loader, net, criterion, device)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.5987379193305968\n",
            "\n",
            "Start training\n",
            "-----------------Epoch = 1-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 1] loss: 0.825 elapsed time 24.103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.187025147676468\n",
            "-----------------Epoch = 2-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 2] loss: 0.932 elapsed time 24.130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.3019670307636262\n",
            "-----------------Epoch = 3-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 3] loss: 0.875 elapsed time 24.100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.2534922122955323\n",
            "-----------------Epoch = 4-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 4] loss: 0.757 elapsed time 24.187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.181174397468567\n",
            "-----------------Epoch = 5-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 5] loss: 0.917 elapsed time 24.203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.1197853207588195\n",
            "-----------------Epoch = 6-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 6] loss: 0.826 elapsed time 24.223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.3037969470024109\n",
            "-----------------Epoch = 7-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 7] loss: 0.888 elapsed time 24.182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.2846005588769913\n",
            "-----------------Epoch = 8-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 8] loss: 0.818 elapsed time 24.193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.287230807542801\n",
            "-----------------Epoch = 9-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 9] loss: 0.754 elapsed time 24.191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.2953321129083633\n",
            "-----------------Epoch = 10-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[epoch 10] loss: 0.784 elapsed time 24.190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.1396387815475464\n",
            "\n",
            "Finished Training, Testing on test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:51<00:00,  2.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.6356376252676312\n",
            "\n",
            "Generating Unlabeled Result\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/114 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e514da36b60d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nGenerating Unlabeled Result'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./models/model_{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0014eca77934>\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(testloader, net, device, folder)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0msave_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./{}/y{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0msave_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./{}/gt{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             plt.imsave(\n",
            "\u001b[0;32m<ipython-input-4-0014eca77934>\u001b[0m in \u001b[0;36msave_label\u001b[0;34m(label, path)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhex2rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbitdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output_test/y0.png'"
          ]
        }
      ]
    }
  ]
}